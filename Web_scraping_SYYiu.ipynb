{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Web Crawler Program\n",
    "\n",
    "Name: Sau Yee Yiu\n",
    "\n",
    "Python Version: Python 3\n",
    "\n",
    "In this program, the customer reviews of Myer (an upmarket department store chain in Australia) collected from the Trustpilot website (https://au.trustpilot.com/) is used as an example to demonstrate how a Python package can be created to scape all customer reviews from that website and prepare a dataset for later sentiment analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries needed for web scaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initially, try fetch the content of the first page\n",
    "\n",
    "Fisrt use BeautifulSoup to parse the HTML data collected from get() function, and store the data in BeautifulSoup format called ‘soup.’ Then use BeautifulSoup’s prettify function to examine th structure of the underlying HTML in the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Specify the web page for scraping\n",
    "page = requests.get('https://au.trustpilot.com/review/www.myer.com.au')\n",
    "print(page.status_code)\n",
    "#Parse the HTML into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get the title of the page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the title of the page\n",
    "title = soup.title\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Retrieving the target content of the first web page\n",
    "\n",
    "use the find_all method to find all customer reviews on the web page. Using Chrome DevTools to examine the html, each customer review is found to be stored in a 'div' container with a class attribute name \"review-card\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use find_all() to extract all the div containers that have a class attribute review-card\n",
    "myer_reviews = soup.find_all('div', class_='review-card')\n",
    "print(type(myer_reviews))\n",
    "print(len(myer_reviews)) #print total number of customer reviews on first webpage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract customer reviews data on the first webpage\n",
    "\n",
    "The following shows how to extract the reviewer's name, total number of reviews written by the reviewer, the 1-5 stars review rating, title of review and the text review from each review listed in myer_reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_name = []\n",
    "reviewer_count=[]\n",
    "review_rating=[]\n",
    "review_title=[]\n",
    "review_details=[]\n",
    "\n",
    "#extract each review from the div container (i.e., myer_reviews)\n",
    "for r in myer_reviews:\n",
    "#get the name of a reviewer\n",
    "    ID=r.find('div', class_='consumer-information__name').text\n",
    "    reviewer_name.append(ID.strip())\n",
    "#get the numbers of reviews written by the reviewers\n",
    "    r_count=r.find('span').text\n",
    "    #remove the word review from_r_count\n",
    "    index=r_count.find(' review')\n",
    "    r_count_sub=int(r_count[:index])\n",
    "    reviewer_count.append(r_count_sub)\n",
    "#get the title of the review\n",
    "    r_title=r.find('h2', class_='review-content__title').text\n",
    "    review_title.append(r_title.strip()) #strip method removes the '\\n' characters in r_title\n",
    "#get the reviewer rating\n",
    "    r_rate=r.find('img')['alt']\n",
    "    #only extract the text in r_rate\n",
    "    index=r_rate.find(': ')\n",
    "    review_rating.append(r_rate[index+2:])\n",
    "#get the details of the review\n",
    "    r_text = r.find('p', class_='review-content__text').text\n",
    "    review_details.append(r_text.strip()) #strip method removes the '\\n' characters in r_text\n",
    "\n",
    "print(len(review_details))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Now extend the method in Step 5 to extract all customer reviews data of Myer (i.e., There are 19 webpages containing customer reviews of Myer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_name = []\n",
    "reviewer_count=[]\n",
    "review_rating=[]\n",
    "review_title=[]\n",
    "review_details=[]\n",
    "\n",
    "page_no=[str(i) for i in range(1,20)] #total number of pages is 20.\n",
    "\n",
    "for page in page_no:\n",
    "    if page=='1':\n",
    "      #Specify with which web page you are going to be scraping\n",
    "      web = requests.get('https://au.trustpilot.com/review/www.myer.com.au')\n",
    "      if web.status_code == 200:\n",
    "        print(\"Succeffully dowloaded page \", page)\n",
    "      else:\n",
    "        print(\"failed to download page \", page)\n",
    "    else:\n",
    "      #Specify with which web page you are going to be scraping\n",
    "      web = requests.get('https://au.trustpilot.com/review/www.myer.com.au?page='+ page)\n",
    "      if web.status_code == 200:\n",
    "        print(\"Succeffully dowloaded page \", page)\n",
    "      else:\n",
    "        print(\"failed to download page \", page)\n",
    "     \n",
    "    #Parse the HTML into the BeautifulSoup parse tree format\n",
    "    soup = BeautifulSoup(web.text, 'html.parser')\n",
    "\n",
    "    #use find_all() to extract all the div containers that have a class attribute review-card\n",
    "    myer_reviews = soup.find_all('div', class_='review-card')\n",
    "    #extract each review from the div container (i.e., myer_reviews)\n",
    "    for r in myer_reviews:\n",
    "        #get the name of a reviewer\n",
    "        ID=r.find('div', class_='consumer-information__name').text\n",
    "        reviewer_name.append(ID.strip())\n",
    "        #get the numbers of reviws written by the reviewers\n",
    "        r_count=r.find('span').text\n",
    "        #remove the word review from_r_count\n",
    "        index=r_count.find(' review')\n",
    "        r_count_sub=int(r_count[:index])\n",
    "        reviewer_count.append(r_count_sub)\n",
    "        #get the title of the review\n",
    "        r_title=r.find('h2', class_='review-content__title').text\n",
    "        review_title.append(r_title.strip())\n",
    "        #get the reviewer rating\n",
    "        r_rate=r.find('img')['alt']\n",
    "        #just extract rating text\n",
    "        index=r_rate.find(': ')\n",
    "        review_rating.append(r_rate[index+2:])\n",
    "        #get the details of the review\n",
    "        r_text = r.find('p', class_='review-content__text').text\n",
    "        review_details.append(r_text.strip())\n",
    "      \n",
    "    #control the loop rate using the sleep() function\n",
    "    sleep(3)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Convert the data collected from Step 6 to Python’s panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myer_reviews = pd.DataFrame({'reviewer name': reviewer_name, 'number of reviews by reviewer': reviewer_count, \n",
    "                              'review title': review_title, 'review rating': review_rating,\n",
    "                               'review' : review_details})\n",
    "myer_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save as CSV file\n",
    "\n",
    "Save the dataframe content to a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = myer_reviews.to_csv ('myer_customer_reviews.csv', index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
