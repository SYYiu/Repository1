{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxNN_gcdcPyN"
   },
   "source": [
    "## Customer Sentiment Analysis\n",
    "\n",
    "Name: Sau Yee Yiu\n",
    "\n",
    "Python Version: Python 3\n",
    "\n",
    "In this program, an data exploration is conducted on the collected customer reviews of Myer dataset (\"myer_customer_reviews.csv\") to get an initial understanding of the customer sentiments. Then a sentiment analysis model is implemented and applied to the actual \"review\" text data in the collected data to classify customer reviews into positive, negative or neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tRYkRM5cPyV"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWdRC7gncPye"
   },
   "source": [
    "Step 1: Create a Spark Session\n",
    "\n",
    "Create a SparkSession that loads settings from system properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBAUxK5EcPyg"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D1B5LAS0cPyp"
   },
   "source": [
    "Step 2: Load the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iYN9HG-cPys"
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"reviewer name\", StringType(), True),\n",
    "    StructField(\"number of reviews by reviewer\", IntegerType(), True),\n",
    "    StructField(\"review title\", StringType(), True),\n",
    "    StructField(\"review rating\", StringType(), True),\n",
    "    StructField(\"review\", StringType(), True)])\n",
    "\n",
    "reviews_data = spark.read.format(\"org.apache.spark.csv\").option(\"delimiter\",\",\").schema(schema).option(\"header\", \"True\").option(\"inferSchema\", \"True\").csv(\"/content/drive/My Drive/Colab Notebooks/myer_customer_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rk2r92x8cstf"
   },
   "source": [
    "Step 3: Initial Data Exploration  - Fetch “Number of Reviews Written”\n",
    "\n",
    "Fetch column: “Number of Reviews Written” to analyse number of reviews writtten by every customer that submitted a review of the Myer store on the TrustPilot website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "sV4OFUuWdq6J",
    "outputId": "729a0879-4b91-46c2-f645-c30d9df947a6"
   },
   "outputs": [],
   "source": [
    "reviewscount_rdd = reviews_data.select(\"number of reviews by reviewer\").rdd.flatMap(lambda x: x)\n",
    "reviewscount_rdd.collect()\n",
    "max_count=max(reviewscount_rdd.collect())\n",
    "\n",
    "#visualise the output\n",
    "bins, counts = reviewscount_rdd.histogram(max_count)\n",
    "print(counts)\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts)\n",
    "plt.xlabel('number of reviews posted')\n",
    "plt.ylabel('number of reviewers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SsAahK0cPyy"
   },
   "source": [
    "Fetch “review rating”\n",
    "    \n",
    "Fetch column: “review rating” to analyse customers' overall rating to Myer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "y6LuHkyFcPy2",
    "outputId": "7bf42f3f-5a4a-44d4-f52b-c2019a9489f8"
   },
   "outputs": [],
   "source": [
    "reviewrate_rdd = reviews_data.select(\"review rating\").rdd.flatMap(lambda x: x)\n",
    "reviewrate_rdd.collect()\n",
    "reviewrate_rdd.take(10)\n",
    "\n",
    "#visualise the output\n",
    "rrate=reviewrate_rdd.countByValue()\n",
    "print(rrate)\n",
    "\n",
    "plt.bar(range(len(rrate)), list(rrate.values()), align='center')\n",
    "plt.xticks(range(len(rrate)), list(rrate.keys()))\n",
    "plt.xlabel('customer review rating')\n",
    "plt.ylabel('number of reviewers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cslX_6QscPy-"
   },
   "source": [
    "Step 4: Fetch column “review\" and prepare the text corpus for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "cZq-tZIgAP4u",
    "outputId": "f73a740f-1151-4525-d1a6-c33ef06cc0f0"
   },
   "outputs": [],
   "source": [
    "reviews_rdd = reviews_data.select(\"review\").rdd.flatMap(lambda x: x)\n",
    "lowerCase_reviewsrdd = reviews_rdd.map(lambda x : x.lower())\n",
    "lowerCase_reviewsrdd.collect()\n",
    "lowerCase_reviewsrdd.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgkztUA9Fxr6"
   },
   "source": [
    "Step 5: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "q36M1wvAF3AG",
    "outputId": "763fe2fc-9683-4dd3-e7e4-faf85495f742"
   },
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer() \n",
    "\n",
    "sentimentRDD = lowerCase_reviewsrdd.map(lambda x:analyzer.polarity_scores(x))\n",
    "sentimentRDD.collect()\n",
    "sentimentRDD.take(3)\n",
    "\n",
    "field_list =['compound']\n",
    "\n",
    "#function for filtering a dictionary by key\n",
    "def filterlist(x):\n",
    "    d = {}\n",
    "    for k in x:\n",
    "        if k in field_list:\n",
    "            d[k] = x.get(k)\n",
    "    return d\n",
    "\n",
    "#use the compound scores only\n",
    "rdd_subset = sentimentRDD.map(lambda x: filterlist(x))\n",
    "rdd_subset.collect()\n",
    "print(rdd_subset.take(3))\n",
    "\n",
    "#use the compound score to determine if the review is positive, negative or neutral\n",
    "def analyse_sentiment(polarityscore):\n",
    "    if polarityscore.get('compound')> 0:\n",
    "       return \"positive\"\n",
    "    elif polarityscore.get('compound') == 0:\n",
    "       return \"neutral\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "\n",
    "sentiment_rate=rdd_subset.map(lambda x: analyse_sentiment(x))\n",
    "sentiment_rate.collect()\n",
    "sentiment_rate.take(10)\n",
    "\n",
    "#visualise the output\n",
    "sentiment_results=sentiment_rate.countByValue()\n",
    "print(sentiment_results)\n",
    "\n",
    "plt.bar(range(len(sentiment_results)), list(sentiment_results.values()), align='center')\n",
    "plt.xticks(range(len(sentiment_results)), list(sentiment_results.keys()))\n",
    "plt.xlabel('customer review categories')\n",
    "plt.ylabel('number of reviewers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zRm-d1CecPzK"
   },
   "source": [
    "Step 6: Extract keywords from the review title for further analyses (optional)\n",
    "\n",
    "First, tokenise each sentence in a review first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "ecKpV-6YcPzN",
    "outputId": "99a04034-7c12-41f0-c8c2-cdee68f0e3d7"
   },
   "outputs": [],
   "source": [
    "reviewst_rdd = reviews_data.select(\"review title\").rdd.flatMap(lambda x: x)\n",
    "lowerCase_reviewstrdd = reviewst_rdd.map(lambda x : x.lower())\n",
    "lowerCase_reviewstrdd.collect()\n",
    "lowerCase_reviewstrdd.take(10)\n",
    "nltk.download('punkt')\n",
    "\n",
    "#define a function for sentence tokenization\n",
    "def sent_Tokenize(x):\n",
    "    return nltk.sent_tokenize(x)\n",
    "\n",
    "sentenceTokensRDD = lowerCase_reviewstrdd.map(sent_Tokenize)\n",
    "\n",
    "sentenceTokensRDD.collect()\n",
    "\n",
    "sentenceTokensRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZ5MbpyRcPzU"
   },
   "source": [
    "Then tokenize each word in all sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "s_ZFIOsIcPzY",
    "outputId": "c6ff75df-3455-489f-9d24-eaca5aa4bc60"
   },
   "outputs": [],
   "source": [
    "#define function for tokenise each word in a sentence\n",
    "def word_Tokenize(x):\n",
    "    w_token = [word for line in x for word in line.split()]\n",
    "    return w_token\n",
    "\n",
    "wordTokensRDD = sentenceTokensRDD.map(word_Tokenize)\n",
    "\n",
    "wordTokensRDD.collect()\n",
    "\n",
    "wordTokensRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzBrSSdScPzi"
   },
   "source": [
    "Remove all stop words and punctations from the word tokens list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHfdRikDcPzk"
   },
   "outputs": [],
   "source": [
    "def removeStopWords(x):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words=stopwords.words('english')\n",
    "    stop_words.append('…')\n",
    "    filtereds = [w for w in x if not w in stop_words]\n",
    "    return filtereds\n",
    "\n",
    "stopwordRDD = wordTokensRDD.map(removeStopWords)\n",
    "\n",
    "\n",
    "def removePunctuations(x):\n",
    "    list_punct=list(string.punctuation)\n",
    "    filteredp = [''.join(c for c in s if c not in list_punct) for s in x] \n",
    "    filtered_sp = [s for s in filteredp if s] #remove empty space \n",
    "    return filtered_sp\n",
    "\n",
    "filteredPunctRDD = stopwordRDD.map(removePunctuations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2idwo0WoQ7Uy"
   },
   "source": [
    "Extract the top 30 keywords from filteredPunctedRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dDhoHK-cP0g"
   },
   "outputs": [],
   "source": [
    "freqDistRDD = filteredPunctRDD.flatMap(lambda x : nltk.FreqDist(x).most_common()).map(lambda x: x).reduceByKey(lambda x,y : x+y).sortBy(lambda x: x[1], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRpGgMlqcP0p"
   },
   "source": [
    "Step 13: Visualize the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "OBHV9x7oRmiS",
    "outputId": "794008fe-89c9-4fd2-bafa-0191ff76fe57"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "df_fDist = freqDistRDD.toDF() #converting RDD to spark dataframe\n",
    "df_fDist.createOrReplaceTempView(\"myTable\") \n",
    "df2 = spark.sql(\"SELECT _1 AS Keywords, _2 as Frequency from myTable limit 30\") #renaming columns \n",
    "Top30words = df2.toPandas() #converting spark dataframes to pandas dataframes\n",
    "Top30words.plot.barh(x='Keywords', y='Frequency', rot=1, figsize=(10,8))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Customer_Sentiment_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
